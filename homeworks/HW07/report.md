# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Выбраны 3 датасета из 4:

- `S07-hw-dataset-01.csv`

- `S07-hw-dataset-02.csv`

- `S07-hw-dataset-03.csv`

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: 12000 строк, 9 столбцов
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: разные масштабы признаков, данные могут содержать шумы из-за больших разбросов у некоторых признаков

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: 8000 строк, 4 столбца
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: признак *z_noise* существенно отличается по масштабу и имеет значительно больший разброс, что может указывать на наличие шумов или выбросов

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: 15000 строк, 5 столбцов
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: разное масштабирование у признаков

## 2. Protocol

- Препроцессинг: так как в данных присутствуют только числовые признаки без пропусков, было использовано только масштабирование (*scaling*) для числовых признаков `StandardScaler`.

- Поиск гиперпараметров:
  - Для `KMeans` был подбор параметра *n_clusters* в диапазоне от 2 до 20 (включительно). Для `DBSCAN` был подбор параметров *eps* в диапазоне `[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]`и *min_samples* в диапазоне `[3, 5, 7, 10]`
  - В качестве основной метрики для оценки качества кластеризации выбран **`Silhouette-score`** , потому что он одновременно оценивает насколько точки близки к своему центру кластера и насколько далеки от соседних кластеров. Это позволяет избежать ситуаций, когда кластеры либо слишком размазаны, либо неестественно дробятся. 

- Метрики: для каждой модели считались следующие метрики: `silhouette`,  `Davies-Bouldin`,  `Calinski-Harabasz`. Для `DBSCAN` метрики оценивались без учета шума. 

- Визуализация: PCA(2D), k vs silhouette-score (для `KMeans`).

## 3. Models

На каждом датасете использовались следующие методы кластеризации:

- `KMeans` с поиском `k` в диапазоне от 2 до 20 (включительно). Фиксировались `n_init=10` и `random_state=39` для каждой конфигурации. Лучшая модель выбиралась с помощью максимизации `silhouette-score`.

- `DBSCAN`. Лучшая модель выбиралась с помощью максимизации `silhouette-score` на нешумовых точках с учетом процента шумовых точек (оценка интерпретируемости модели). Гиперпараметры для подбора:

  - `eps`: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8] - радиус окрестности

  - `min_samples`: [3, 5, 7, 10] - минимальное число точек для образования кластера


## 4. Results

### 4.1 Dataset A

- Лучший метод и параметры: `KMeans` с параметром `k=2`

- Метрики (silhouette / DB / CH):
  - `silhouette`=0.522
  - `Davies-Bouldin`=0.685
  - `Calinski-Harabasz`=11786.955

- `DBSCAN`: доля шума 1.9%. Умеренный шум, но `DBSCAN` разделил на 5 кластеров в первом датасете и проиграл по метрикам `KMeans`

- Вывод: `KMeans` продемонстрировал явное преимущество по всем метрикам качества.

### 4.2 Dataset B

- Лучший метод и параметры: `KMeans` с параметром `k=2`
  
- Метрики (silhouette / DB / CH):
  - `silhouette`=0.307
  - `Davies-Bouldin`=1.323
  - `Calinski-Harabasz`=3573.393

- `DBSCAN`: доля шума 91.8%. Около 92% данных выпали из кластеризации, а оставшиеся разделил по плотности в 46 кластеров, что неприемлемо для практического применения.

- Вывод: `KMeans` немного проиграл `DBSCAN` по основным метрикам, но создал осмысленное разделение на две сбалансированные группы, что лучше соответствует задаче поиска общей структуры во всём датасете


### 4.3 Dataset C

- Лучший метод и параметры: `KMeans` с параметром `k=3`
  
- Метрики (silhouette / DB / CH):
  - `silhouette`=0.316
  - `Davies-Bouldin`=1.158
  - `Calinski-Harabasz`=6957.163

- `DBSCAN`: доля шума 99.6%. `DBSCAN` показал исключительно высокий силуэт-коэффициент (0.812) и очень низкий индекс Дэвиса-Болдина (0.245), что говорит об идеальном разделении тех немногих точек, которые алгоритм смог отнести к кластерам. Такой результат, хоть и метрически превосходный, совершенно бесполезен из-за отделения почти всех данных как шум, а оставшиеся 0.4% данных бесполезны для анализа датасета.

- Вывод: `KMeans` с *k=3*, несмотря на скромные метрические показатели, дал осмысленное и сбалансированное разделение на три группы, охватывающее все точки датасета. Высочайший процент шума, выявленный `DBSCAN`, свидетельствует о том, что данные практически полностью состоят из выбросов с точки зрения плотностной кластеризации.


## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- `KMeans` ломается на данных с несферическими кластерами, неравномерной плотностью и значительными выбросами. Он предполагает сферические кластеры равного размера и чувствителен к выбросам, которые смещают центроиды. Модель пытается включить все точки в кластеры, "размазывая" центроиды под влиянием выбросов. ДОБАВИТЬ ПОЧЕМУ
- `DBSCAN` же явно выделяет выбросы как шум (-1), поэтому он выигрывает там, где нужно выделять кластеры произвольной формы и автоматически определять выбросы. Модель не требует указания числа кластеров и хорошо работает с данными разной плотности, выделяя плотные области как отдельные кластеры.
- На результат сильнее всего влияли масштабирование признаков (без него алгоритмы работали некорректно), наличие выбросов (определяло выбор между `KMeans` и `DBSCAN`) и плотность распределения данных (критично для `DBSCAN`). Категориальных признаков и пропусков не было.

### 5.2 Устойчивость (обязательно для одного датасета)

- В ходе проверки устойчивости было выполнено 5 запусков модели `KMeans` с лучшими параметрами для датасета C и перебрано 5 значений `random_state` ([42, 123, 456, 789, 999]).

`KMeans` продемонстрировал хорошую устойчивость при различных инициализациях. Adjusted Rand Index (ARI) между всеми запусками составил 1.0000, что означает полное совпадение кластеризаций независимо от выбранного *random_state*.

- Silhouette Score: Все 5 запусков показали идентичное значение 0.3155

- Davies-Bouldin Index: Константное значение 1.1577

- Calinski-Harabasz Index: Стабильное значение 6957.2 

- Inertia: Практически одинаковое значение 31123.45 (минимальные колебания +-0.01)


- Вывод: Для датасета `S07-hw-dataset-03.csv` модель `KMeans` с параметром *k=3* является довольно устойчивым, так как алгоритм демонстрирует стабильные метрики качества при различных инициализациях (*random_state*).

### 5.3 Интерпретация кластеров

Для интерпретации кластеров использовалась визуальная оценка распределения данных после PCA-проекции и анализ метрик качества. 

Датасет A демонстрировал наиболее четкую структуру. `KMeans` с k=2 создал два хорошо разделенных кластера с высоким `silhouette-score`, что визуально подтверждалось PCA-проекцией: точки образовывали две группы с минимальным перекрытием.

Датасет B представлял более сложный случай. `KMeans` с k=2 формально проигрывал `DBSCAN` по метрикам, но давал осмысленное разделение на две группы. Визуально в PCA-пространстве кластеры имели большее перекрытие, что объясняло более низкий `silhouette-score`. При этом кластеры оставались сбалансированными и охватывали весь датасет, в отличие от DBSCAN, который выделил 46 микро-кластеров из лишь 8% данных.

Датасет C показал предельный случай для плотностных методов. `KMeans` с k=3 создал три группы с умеренным качеством, но охватывающие все данные. Визуально в PCA наблюдалось три облака точек с заметным перекрытием. DBSCAN же, формально получив отличные метрики, оказался практически бесполезен, классифицировав 99.6% данных как шум.


## 6. Conclusion

Проведенный эксперимент по сравнению алгоритмов кластеризации KMeans и DBSCAN позволил сформулировать несколько важных выводов. 

Во-первых, метрики качества кластеризации необходимо оценивать критически — высокие значения silhouette-score могут достигаться за счет исключения большей части данных как шума, что делает результат формально хорошим, но практически бесполезным. 

Во-вторых, выбор алгоритма должен определяться не только метриками, но и природой данных: KMeans лучше подходит для поиска общей структуры во всем датасете, а DBSCAN — для выделения плотных ядер и обнаружения аномалий. В-третьих, предобработка данных (особенно масштабирование) оказывает решающее влияние на работу обоих алгоритмов.
